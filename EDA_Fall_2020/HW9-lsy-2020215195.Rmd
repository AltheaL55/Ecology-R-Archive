---
title: "HW9"
author: "Lsy"
date: "2020/11/12"
output: word_document
---
Check out the trends of Cyclops and Diaptomus under the influences of environmental factors, and do they have similar trends as Green and Blue-green algae? Why? Any changes if include the seasonal trend?

```{R prepare}
setwd("D:/ELsy/2020fall/EDA/9/Lab9notes") 
library(nlme)
library (imputeTS) 
library(strucchange) 
library(mgcv)
library(mvtnorm)
library(KFAS)
library(MARSS)
```
Data overview
The data set (Example.csv) used in this part of lab contains measurements made in Lake Washington on concentrations of different plankton species and the environmental conditions. 
```{r}
# Read in data 
fulldat<-read.csv("example.csv") 
# We extract out temperature to run the analysis 
datat<-fulldat[,7] 
# We create a time series from this data 
data<-ts(datat,start=c(1965,1), end=c(1994,12), freq=12) 
plot(data)
# There are missing values in the time series, we need to impute the value so ACF can be run 
data2<-na_interpolation(data) 
# plot,showing where missing values were filled 
ggplot_na_distribution(data)
```



ACF
Auto-Correlation Function (ACF) calculates correlations of a series with itself at different lags, which allows estimating how long the historical effect is felt, as well as identifying cycles in the time series. More information with ?acf(). Significant cross-correlations cross the blue dashed line.

```{r}
#Preparing a multipanel figure 
par(mfrow=c(1,3)) 
# Calculate ACF
acf(data2) 
# The same analysis can be done on detrended data by differencing the time series 
# (with the function diff()), which allows identifying auto-correlation patterns in 
# terms of the rates of change. 
acf(diff(data2)) 
# # A complementary approach to study autocorrelation is using periodograms, which show
# the density of the time series at different frequencies (i.e. for cycles with different 
# periods). The null hypothesis for uncorrelated data is a horizontal line (all frequencies equally important). 
# Important cycles in the time series appear as peaks in density. 
# Ecological systems tend to decrease density with increasing frequency.
spec.pgram(data2,plot=T,detrend=T)
```

Simple temporal analysis 

```{r}
# We extract out both time and value for Diatoms 
time<-fulldat[,1] 
data<-fulldat[,7]
# BEFORE-AFTER COMPARISON
# The time series is split in two (half way through the time series in this example). 
# and a box plot is used to compare the two time periods. A t-test shows that the two periods are # significantly different. 
bRegime2<-time>=time[ceiling(length(time)/2)] 
boxplot(data~bRegime2,notch=FALSE,names=c('period1','period2'),ylab='',fontsize=14,lwd=2,main="") 
t.test(data~bRegime2)
```


GLOBAL TREND The global trend can be obtained by performing a linear regression with the biodiversity metric as a function of time. Multiple predictors can be used in a similar framework. 
```{r}
# Create a new data frame 
dt<-cbind(data,time)
head(dt) 
# Create a new time variable,the next step does not allow duplicated value in time variable 
Time<-seq(from = 1, to = 396, by =1) 
str(dt) 
# Combine dat
dat<-as.data.frame(cbind(dt,Time)) 
# Trend estimated using Ordinary Least Squares 
ols.trend<-lm(data~Time,data=dat) 
# # Trend estimated using Generalized Least Squares, which allows the use 
# of autoregressive error in a bid to deal with temporal autocorrelation. 
# in this case we use a an autoregressive process of order 1 
gls.trend<- gls(data~Time, correlation =corAR1(form=~Time),na.action = na.omit, data=dat)
# plotting shows that the two methods estimate very similar global trends 
plot(dat$Time, dat$data, type="l", col="grey", lwd=3) 
abline(ols.trend, lty=1, lwd=2) 
abline(gls.trend, lty=2, lwd=2) 
# However, examining the test statistics shows that the gls approach has more 
# conservative p-values because it adjusts for autocorrelation in the data # 
summary(ols.trend)
summary(gls.trend)
```
LOCAL TREND 
```{r}
plot(dat$Time, dat$data, type="l", col="grey") 
# Local trends can be visually examined by using smoothing functions 
# such as moving averages or locally weighed scatterplot smoothing (LOESS) 
lines(loess.smooth(dat$Time,dat$data),lty=1, lwd=2) 
# smoothing terms can also be incorporated in Generalized Additive Models
# to allow non-linear functions of predictors. More information with ?gam 
gam.mod<-gam(data~s(Time))
timedf<-data.frame(Time) 
yhat<-predict(gam.mod,timedf) 
# note that to generate gam predictions we must use the function predict, 
# which needs the predictors to be supplied in a data frame format 
lines(Time,yhat, lty=2, lwd=2) # The plot shows that both approaches identify time intervals with different trends
```

BREAKPOINT DETECTION 
Assessing deviations from stability in a regression model allows identifying time periods with different linear trends. This is particularly useful in the context of biodiversity time series to detect phase-shifts 
```{r}
# remove na from data, this is done for saving some time. A better way is to fill in the missing data. 
dat2<-na.omit(dat)
str(dat2)
# estimating the location of optimal breakpoints 
bps=breakpoints(dat2$data~1)
summary(bps)
# # comparing models with 0 to 2 breakpoints
mbp0=lm(dat2$data~1)
mbp1=lm(dat2$data~breakfactor(bps,breaks=1)) 
summary(mbp1) 
mbp2=lm(dat2$data~breakfactor(bps,breaks=2)) 
anova(mbp0,mbp1) 
anova(mbp1,mbp2) 
# Plotting the different lines shows a marked difference between # 0 and 1 breakpoint, but a much smaller difference for the second # breakpoint 
plot(dat2$Time, dat2$data, type="l", col="grey", lwd=3)
lines(dat2$Time, ts(fitted(mbp0),start=1),lwd=2,lty=1) 
lines(dat2$Time, ts(fitted(mbp1),start=1),lwd=2,lty=2)
lines(dat2$Time, ts(fitted(mbp2),start=1),lwd=2,lty=3)
```

Part II 
Analysis of multivariate time-series using the MARSS package
The MARSS package provides maximum-likelihood parameter estimation for constrained and unconstrained linear multivariate autoregressive state-space (MARSS) fit to multivariate time-series data.
Note
• You need to install package MARSS before this exercise. #
Demean observations and standardize observations
We use the 10 years of data from 1965-1974, a decade with particularly high green and bluegreen algae levels. We use the transformed plankton dataset which has 0s replaced with NAs. Below, we set up the data and z-score the data. 
```{r}
fulldat<-read.csv("Example.csv")
# Subset data to get observations between 1965 and 1975 
years = fulldat[,"Year"]>=1965 & fulldat[,"Year"]<1975 
# Transpose data 
dat = t(fulldat[years,c("Greens", "Bluegreens")]) # Demean the data and standardize the data 
the.mean = apply(dat,1,mean,na.rm=TRUE)# calculate row mean 
the.sigma = sqrt(apply(dat,1,var,na.rm=TRUE)) #calculate row sigma 
dat = (dat-the.mean)*(1/the.sigma)
```
Demean and standardize two covariates: Temperature and total P
Next we set up the covariate data, temperature and total phosphorous. We z-score the covariates to standardize and remove the mean. 
```{r}
covariates = rbind(Temp = fulldat[years,"Temp"], TP = fulldat[years,"TP"]) # z.score the covariates 
the.mean = apply(covariates,1,mean,na.rm=TRUE) 
the.sigma = sqrt(apply(covariates,1,var,na.rm=TRUE)) 
covariates = (covariates-the.mean)*(1/the.sigma)
```

Plot time series
The function ts is used to create time-series objects. We will plot time series of Green and Bluegreen algae abundances in Lake Washington along with the temperature and total phosporous covariates. 
```{r}
# combine all data and make a time series using fuction ts(), this is # very important!!! 
LWA <- ts(cbind(Year=fulldat[years,"Year"], t(dat), t(covariates)), start=c(1965,1), end=c(1974,12), freq=12) 
plot.ts(LWA[,c("Greens","Bluegreens", "Temp", "TP")], main="", yax.flip=TRUE)
```

Fit process-error only model
Now let’s model the data as an autoregressive process observed without error, and incorporate the covariates into the process model. Note that this is much different from typical linear regression models. Here is our new process model for plankton abundance:
𝑥𝑡=𝑥𝑡−1+𝐶𝑐𝑡+𝑤𝑡, where 𝑤𝑡∼𝑀𝑉𝑁(0,𝑄) 
```{r}
# Assume the data ere observed without error, # data at t-1 affect data at t 
R = A = U = "zero"
B = Z = "identity" 
Q = "equalvarcov" 
C = "unconstrained" 
x = dat # to show the relation between dat & the equations

model.list = list(B=B,U=U,Q=Q,Z=Z,A=A,R=R,C=C,c=covariates) 
kem = MARSS(x, model=model.list) 
coef(kem, type="vector") #show the estimated parameter elements as a vector
```
The data are fluctuating about some mean so let’s switch to a better autoregressive model—a mean-reverting model. To do this, we will allow the diagonal elements of B to be something other than 1 # Fit a mean-reverting model # Allow B to be different than 1 # you may get a better result if your data are flucuating about some mean 
```{r}
model.list$B = "diagonal and unequal" 
kem = MARSS(dat, model=model.list)
#Notice that the log-likelihood goes up quite a bit, which means that the mean-reverting model fits the data much better.
#With this model, we are estimating 𝑥0. If we do not estimate 𝑥0, you can let the data determine coefficients: # let the data determine coefficients 
x0 = dat[,1,drop=FALSE] 
model.list$tinitx = 1 
model.list$x0 = x0 
kem = MARSS(dat, model=model.list)
```
Both process- & observation-error model
The MARSS package is really designed for state-space models where you have errors (𝑣 and 𝑤) in both the process and observation models.
𝑥𝑡=𝑥𝑡−1+𝐶𝑐𝑡+𝑤𝑡, where 𝑤𝑡∼𝑀𝑉𝑁(0,𝑄)
𝑦𝑡=𝑥𝑡−1+𝑣𝑡, where 𝑣𝑡∼𝑀𝑉𝑁(0,𝑅)
𝑥 is the true algae abundances and 𝑦 is the observation of the 𝑥’s.
If you know the variance for your observation, you can add it to the model, then the model deal with both process- and observation- error.Let’s say we knew that the observation variance on the algae measurements was about 0.16 and we wanted to include that known value in the model. 
```{r}
# Here the observation varliance is 0.16
model.list$R = diag(0.16,2)
# the second number corresponds to numbers of Y 
kem = MARSS(dat, model=model.list)
```
### Including *seasonal effects* in MARSS models
Time-series data are often collected at intervals with some implicit “seasonality.” In those cases, it is often helpful to extract any recurring seasonal patterns that might otherwise mask some of the other temporal dynamics we are interested in examining.
Here we show a few approaches for including seasonal effects using the Lake Washington plankton data, which were collected monthly. The following examples will use all five phytoplankton species from Lake Washington.
First, let’s set up the data.
```{r}
 # Load data 
years = fulldat[,"Year"]>=1965 & fulldat[,"Year"]<1975 
phytos = c("Diatoms", "Greens", "Bluegreens", "Unicells", "Other.algae")
dat = t(fulldat[years,phytos]) ## Demean observations and standardize observations # z.score data because we changed the mean when we subsampled 
the.mean = apply(dat,1,mean,na.rm=TRUE) 
the.sigma = sqrt(apply(dat,1,var,na.rm=TRUE)) 
dat = (dat-the.mean)*(1/the.sigma) # number of time periods/samples 
TT = dim(dat)[2]
```

1. Seasonal effects as fixed factors
One common approach for estimating seasonal effects is to treat each one as a fixed factor, such that the number of parameters equals the number of “seasons”. The plankton data are collected monthly, so we will treat each month as a fixed factor.
```{r}
## Set up a matrix to treat month as fixed factor ## Number of "seasons" (e.g., 12 months per year)
period = 12 # first "season" (e.g., Jan = 1, July = 7) 
per.1st = 1 # create factors for seasons
c.in = diag(period)
for(i in 2:(ceiling(TT/period))) {c.in = cbind(c.in,diag(period))} 
# trim c.in to correct start & length
c.in = c.in[,(1:TT)+(per.1st-1)]
# better row names
rownames(c.in) = month.abb
```
Next we need to set up the form of the C matrix which defines any constraints we want to set on the month effects.
```{r}
## Let all five species have the same month effects ## or different month effects,choose one ## Same month effects assigned to five species, C has 12 values
C = matrix(month.abb,5,12,byrow=TRUE) 
C 
# Note, donot run both, only choose one 
# Different month effects for five species, C has # 60 values
C = "unconstrained" 
C
```

Then we set up the form for the rest of the model parameters. We make the following assumptions: 
```{r}
# Each taxon has unique density-dependence
B = "diagonal and unequal" 
# Assume independent process errors 
Q = "diagonal and unequal"
# We have demeaned the data & are fitting a mean-reverting model by estimating a diagonal B, thus 
U = "zero"
# Each obs time series is associated with only one process 
Z = "identity" 
# The data are demeaned & fluctuate around a mean 
A = "zero"
# We assume observation errors are independent, but they have similar variance due to similar collection methods 
R = "diagonal and equal"
# We are not including covariate effects in the obs equation 
D = "zero"
d = "zero"
```

Now we can set up the model list for MARSS and fit the model. 
```{r}
model.list = list(B=B,U=U,Q=Q,Z=Z,A=A,R=R,C=C,c=c.in,D=D,d=d) 
seas.mod.1 = MARSS(dat,model=model.list,control=list(maxit=1500)) 
# Get the estimated seasonal effects 
#rows are taxa, cols are seasonal effects 
seas.1 = coef(seas.mod.1,type="matrix")$C
rownames(seas.1) = phytos 
colnames(seas.1) = month.abb
```
2. Seasonal effects as a polynomial
The fixed factor approach required estimating 60 effects. Another approach is to model the month effect as a 3𝑟𝑑 order (or higher) polynomial. Here we show how to fit a 3𝑟𝑑 order polynomial model.
```{r}
# number of "seasons" (e.g., 12 months per year) 
period = 12
# first "season" (e.g., Jan = 1, July = 7) 
per.1st = 1
# order of polynomial
poly.order = 3
# create polynomials of months 
month.cov = matrix(1,1,period)
for(i in 1:poly.order) {month.cov = rbind(month.cov,(1:12)^i)} 
# our c matrix is month.cov replicated once for each year 
c.m.poly = matrix(month.cov, poly.order+1, TT+period, byrow=FALSE)
# trim c.in to correct start & length 
c.m.poly = c.m.poly[,(1:TT)+(per.1st-1)] 
# Everything else remains the same as in the previous example 
model.list = list(B=B,U=U,Q=Q,Z=Z,A=A,R=R,C=C,c=c.m.poly,D=D,d=d) 
seas.mod.2 = MARSS(dat, model=model.list, control=list(maxit=1500))
# Get the estimated seasonal effects
C.2 = coef(seas.mod.2,type="matrix")$C 
seas.2 = C.2 %*% month.cov
rownames(seas.2) = phytos 
colnames(seas.2) = month.abb
```

3. Seasonal effects as a Fourier series
The factor approach required estimating 60 effects, and the 3𝑟𝑑 order polynomial model was an improvement at only 20 parameters. A third option is to use a discrete Fourier series, which is combination of sine and cosine waves; it would require only 10 parameters. 
```{r}
## Fit a Fourier series 
# Set up a seasonal covariate matrix as a combination of 1 cosine and 1 sine wave 
cos.t = cos(2 * pi * seq(TT) / period) 
sin.t = sin(2 * pi * seq(TT) / period) 
c.Four = rbind(cos.t,sin.t) 
# Fit the model
model.list = list(B=B,U=U,Q=Q,Z=Z,A=A,R=R,C=C,c=c.Four,D=D,d=d)
seas.mod.3 = MARSS(dat, model=model.list, control=list(maxit=1500))
C.3 = coef(seas.mod.3, type="matrix")$C 
# The time series of net seasonal effects
seas.3 = C.3 %*% c.Four[,1:period] 
rownames(seas.3) = phytos 
colnames(seas.3) = month.abb
```

4. Plot estimated monthly effects
Next, we will plot the estimated monthly effects for the three approaches to estimating seasonal effects.
```{r}
par(mfrow=c(3,1), mar=c(2,4,2,2))
matplot(t(seas.1),type="l",bty="n",xaxt="n", ylab="Fixed monthly", col=1:5)
axis(1,labels=month.abb, at=1:12,las=2,cex.axis=0.75)
legend("topright", lty=1:5, legend=phytos, cex=0.6, col=1:5) 
matplot(t(seas.2),type="l",bty="n",xaxt="n", ylab="Cubic", col=1:5)
axis(1,labels=month.abb, at=1:12,las=2,cex.axis=0.75)
legend("topright", lty=1:5, legend=phytos, cex=0.6, col=1:5)
matplot(t(seas.3),type="l",bty="n",xaxt="n",ylab="Fourier", col=1:5) 
axis(1,labels=month.abb, at=1:12,las=2,cex.axis=0.75) 
legend("topright", lty=1:5, legend=phytos, cex=0.6, col=1:5)
```

5. Compare models using AIC
Rather than rely on our eyes to judge model fits, we should formally assess which of the 3 approaches offers the most parsimonious fit to the data. Here is a table of AICc values for the 3 models: 
```{r}
data.frame(Model=c("Fixed", "Cubic", "Fourier"), AICc=round(c(seas.mod.1$AICc, seas.mod.2$AICc, seas.mod.3$AICc),1))
```

6. Model diagnostics
We will examine some basic model diagnostics for these three approaches by looking at plots of the model residuals and their autocorrelation functions (ACFs) for all five taxa using the following code:
Plot individually, here our model 1-3: 
```{r}
### Plot model 1 
par(mfrow=c(5,2), mai=c(0.1,0.5,0.2,0.1), omi=c(0.5,0,0,0))
for(i in 1:5) {
  plot.ts(residuals(seas.mod.1)$model.residuals[i,],
        .tslab="Residual", main=phytos[i], xlab="", xaxt="n") 
  abline(h=0, lty="dashed") 
  if(i==5) {
  axis(1, at=1+seq(0,TT-period,by=12),labels=seq(fulldat[years,"Year"][1],fulldat[years,"Year"][TT])) 
  mtext(side=1, line=2.7, "Time") 
  } 
  acf(residuals(seas.mod.1)$model.residuals[i,], lag.max=period) 
  if(i==5) { 
  axis(1, at=c(0,seq(period))) 
  mtext(side=1, line=2.7, "Time lag") 
  } 
} 
### Plot model 2 
par(mfrow=c(5,2), mai=c(0.1,0.5,0.2,0.1), omi=c(0.5,0,0,0)) 
for(i in 1:5) { 
  plot.ts(residuals(seas.mod.2)$model.residuals[i,], ylab="Residual", main=phytos[i], xlab="", xaxt="n") 
  abline(h=0, lty="dashed") 
  if(i==5) {
    axis(1, at=1+seq(0,TT-period,by=12),labels=seq(fulldat[years,"Year"][1],fulldat[years,"Year"][TT])) 
  mtext(side=1, line=2.7, "Time")
  } 
  acf(residuals(seas.mod.2)$model.residuals[i,], lag.max=period) 
  if(i==5) { 
    axis(1, at=c(0,seq(period))) 
    mtext(side=1, line=2.7, "Time lag") 
  }
} 
### Plot model 3 
par(mfrow=c(5,2), mai=c(0.1,0.5,0.2,0.1), omi=c(0.5,0,0,0)) 
for(i in 1:5) {
  plot.ts(residuals(seas.mod.3)$model.residuals[i,], ylab="Residual", main=phytos[i], xlab="", xaxt="n") 
  abline(h=0, lty="dashed") 
  if(i==5) {
    axis(1, at=1+seq(0,TT-period,by=12),labels=seq(fulldat[years,"Year"][1],fulldat[years,"Year"][TT])) 
    mtext(side=1, line=2.7, "Time") 
    } 
  acf(residuals(seas.mod.3)$model.residuals[i,], lag.max=period)
  if(i==5) {axis(1, at=c(0,seq(period))) 
    mtext(side=1, line=2.7, "Time lag") 
  }
}
```
